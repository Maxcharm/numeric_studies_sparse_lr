{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseLinearDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 total_sequence_length: int = 200, \n",
    "                 sparsity: int = 6,\n",
    "                 num_samples: int = 1000, \n",
    "                 noise_std: float = 0.1,\n",
    "                 input_dist: str = \"gaussian\",\n",
    "                 input_std:int = 5,\n",
    "                 input_range:tuple[float, float] = (-10, 10),\n",
    "                 true_weight_dist: str = \"gaussian\",\n",
    "                 weight_std:int = 5,\n",
    "                 weight_range:tuple[float, float] = (-10, 10),\n",
    "                 coefficient:list[int] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.active_set = torch.randperm(total_sequence_length)[:sparsity]\n",
    "        self.true_weight = torch.zeros(total_sequence_length).int()\n",
    "        self.num_samples = num_samples\n",
    "        if coefficient is not None:\n",
    "            self.true_weight[self.active_set] = coefficient\n",
    "        else:\n",
    "            if true_weight_dist == \"gaussian\":\n",
    "                true_weights = torch.randn(sparsity) * weight_std\n",
    "            else:\n",
    "                assert true_weight_dist == \"uniform\", f\"unknown distribution {true_weight_dist}.\"\n",
    "                low, high = weight_range\n",
    "                true_weights = torch.empty(sparsity).uniform_(low, high)\n",
    "        true_weights = true_weights.int()\n",
    "        self.true_weight[self.active_set] = true_weights\n",
    "        self.data = []\n",
    "        if input_dist == \"gaussian\":\n",
    "            for _ in range(num_samples):\n",
    "                x = torch.randint(0, 10, (total_sequence_length,)).int()\n",
    "                y = x @ self.true_weight + noise_std * torch.randn(1)\n",
    "                x = x.float()\n",
    "                y = y.float()\n",
    "                self.data.append((x, y))\n",
    "        else:\n",
    "            assert input_dist == \"uniform\", f\"unknown input distribution {input_dist}.\"\n",
    "            low, high = input_range\n",
    "            for _ in range(num_samples):\n",
    "                x = torch.empty(total_sequence_length).uniform_(low, high).float()\n",
    "                x = x.int()               \n",
    "                y = x @ self.true_weight + noise_std * torch.randn(1)\n",
    "                x = x.float()\n",
    "                y = y.float()\n",
    "                self.data.append((x, y.item()))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_network(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Linear(in_features=input_dim, out_features=1)\n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_network_hidden(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.ModuleList([\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for layer in self.network:\n",
    "            x = layer(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    (20, 6),\n",
    "    (200, 6),\n",
    "    (2000, 6)\n",
    "]\n",
    "runs = 20\n",
    "epochs = 300\n",
    "# patience = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: noiseless label, inputs and true weights being both i.i.d. gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxcharmhan/miniconda3/envs/sparse/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 - Loss: 533.4336\n",
      "Epoch 20 - Loss: 0.6140\n",
      "Epoch 40 - Loss: 0.4397\n",
      "Epoch 60 - Loss: 0.3089\n",
      "Epoch 80 - Loss: 0.3676\n",
      "Epoch 100 - Loss: 0.1224\n",
      "Epoch 120 - Loss: 0.1957\n",
      "Epoch 140 - Loss: 0.3554\n",
      "Epoch 160 - Loss: 0.2430\n",
      "Epoch 180 - Loss: 0.2775\n",
      "Epoch 200 - Loss: 0.3979\n",
      "Epoch 220 - Loss: 0.1269\n",
      "Epoch 240 - Loss: 0.1689\n",
      "Epoch 260 - Loss: 0.2882\n",
      "Epoch 280 - Loss: 0.0582\n",
      "Epoch 00 - Loss: 42.7005\n",
      "Epoch 20 - Loss: 0.2123\n",
      "Epoch 40 - Loss: 0.1329\n",
      "Epoch 60 - Loss: 0.1597\n",
      "Epoch 80 - Loss: 0.1314\n",
      "Epoch 100 - Loss: 0.1061\n"
     ]
    }
   ],
   "source": [
    "for (n,k) in configurations:\n",
    "    losses_across_runs = []\n",
    "    for _ in range(runs):\n",
    "        losses = []\n",
    "        dataset = SparseLinearDataset(total_sequence_length=n, sparsity=k, num_samples=1600, noise_std=0)\n",
    "        dataloader = DataLoader(dataset, shuffle=True)\n",
    "        true_active_set = dataset.active_set\n",
    "        model = linear_network_hidden(n, 2*k)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 5e-3)\n",
    "\n",
    "        # best_loss = float(\"inf\") \n",
    "        # epochs_without_improvement = 0 # for early stopping\n",
    "\n",
    "        model.train()\n",
    "        loss_fn = nn.MSELoss()\n",
    "        for idx in range(epochs):\n",
    "            total_loss = 0\n",
    "            for (x, y) in dataloader:\n",
    "                preds = model(x)\n",
    "                loss = loss_fn(preds, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            # if avg_loss < best_loss:\n",
    "            #     best_loss = avg_loss\n",
    "            #     epochs_without_improvement = 0\n",
    "            # else:\n",
    "            #     epochs_without_improvement += 1\n",
    "            # if epochs_without_improvement > patience:\n",
    "            #     # final_weight = model.network.weight.data.detach()\n",
    "            #     print(f\"Early stopping at Epoch {idx}, with loss {avg_loss:.4f}.\")\n",
    "            #     break\n",
    "            if idx % 20 == 0:\n",
    "                print(f\"Epoch {idx:02d} - Loss: {avg_loss:.4f}\")\n",
    "            losses.append(avg_loss)\n",
    "        losses_across_runs.append(losses)\n",
    "    np.save(f\"../log/n_{n}_k_{k}_20runs.npy\", np.array(losses_across_runs))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: noiseless label, inputs being gaussian, true weights being uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: noiseless label, inputs and true weights being both uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4: noiseless label, inputs being uniform and true weights being gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 5: noiseless label, inputs being uniform and true weights being 1, -1, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 6: noiseless label, inputs being gaussian and true weights being 1, -1, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
