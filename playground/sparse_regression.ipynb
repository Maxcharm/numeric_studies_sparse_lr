{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseLinearDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 total_sequence_length: int = 200, \n",
    "                 sparsity: int = 6,\n",
    "                 num_samples: int = 1000, \n",
    "                 noise_std: float = 0.1,\n",
    "                 input_dist: str = \"gaussian\",\n",
    "                 input_std:int = 5,\n",
    "                 input_range:tuple[float, float] = (-10, 10),\n",
    "                 true_weight_dist: str = \"gaussian\",\n",
    "                 weight_std:int = 5,\n",
    "                 weight_range:tuple[float, float] = (-10, 10),\n",
    "                 coefficient:list[int] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.active_set = torch.randperm(total_sequence_length)[:sparsity]\n",
    "        self.true_weight = torch.zeros(total_sequence_length).int()\n",
    "        self.num_samples = num_samples\n",
    "        if coefficient is not None:\n",
    "            self.true_weight[self.active_set] = coefficient\n",
    "        else:\n",
    "            if true_weight_dist == \"gaussian\":\n",
    "                true_weights = torch.randn(sparsity) * weight_std\n",
    "            else:\n",
    "                assert true_weight_dist == \"uniform\", f\"unknown distribution {true_weight_dist}.\"\n",
    "                low, high = weight_range\n",
    "                true_weights = torch.empty(sparsity).uniform_(low, high)\n",
    "        true_weights = true_weights.int()\n",
    "        self.true_weight[self.active_set] = true_weights\n",
    "        self.data = []\n",
    "        if input_dist == \"gaussian\":\n",
    "            for _ in range(num_samples):\n",
    "                x = torch.randn(total_sequence_length) * input_std\n",
    "                x = x.int()\n",
    "                y = x @ self.true_weight + noise_std * torch.randn(1)\n",
    "                x = x.float()\n",
    "                y = y.float()\n",
    "                self.data.append((x, y))\n",
    "        else:\n",
    "            assert input_dist == \"uniform\", f\"unknown input distribution {input_dist}.\"\n",
    "            low, high = input_range\n",
    "            for _ in range(num_samples):\n",
    "                x = torch.empty(total_sequence_length).uniform_(low, high).float()\n",
    "                x = x.int()               \n",
    "                y = x @ self.true_weight + noise_std * torch.randn(1)\n",
    "                x = x.float()\n",
    "                y = y.float()\n",
    "                self.data.append((x, y.item()))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_network(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Linear(in_features=input_dim, out_features=1)\n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_network_hidden(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.ModuleList([\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for layer in self.network:\n",
    "            x = layer(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    (20, 6),\n",
    "    (200, 6),\n",
    "    (2000, 6)\n",
    "]\n",
    "runs = 100\n",
    "epochs = 4000\n",
    "patience = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: noiseless label, inputs and true weights being both i.i.d. gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n,k) in configurations:\n",
    "    for _ in range(runs):\n",
    "        dataset = SparseLinearDataset(total_sequence_length=n, sparsity=k, num_samples=16000, noise_std=0)\n",
    "        dataloader = DataLoader(dataset, batch_size=200, shuffle=True)\n",
    "        true_active_set = dataset.active_set\n",
    "        model = linear_network(n)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 2e-3)\n",
    "\n",
    "        best_loss = float(\"inf\") \n",
    "        epochs_without_improvement = 0 # for early stopping\n",
    "\n",
    "        model.train()\n",
    "        loss_fn = nn.MSELoss()\n",
    "        for idx in range(epochs):\n",
    "            total_loss = 0\n",
    "            for (x, y) in dataloader:\n",
    "                preds = model(x)\n",
    "                loss = loss_fn(preds, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                epochs_without_improvement = 0\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "            if epochs_without_improvement > patience:\n",
    "                # final_weight = model.network.weight.data.detach()\n",
    "                print(f\"Early stopping at Epoch {idx}, with loss {avg_loss:.4f}.\")\n",
    "                break\n",
    "            if idx % 20 == 0:\n",
    "                print(f\"Epoch {idx:02d} - Loss: {avg_loss:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: noiseless label, inputs being gaussian, true weights being uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: noiseless label, inputs and true weights being both uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4: noiseless label, inputs being uniform and true weights being gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 5: noiseless label, inputs being uniform and true weights being 1, -1, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 6: noiseless label, inputs being gaussian and true weights being 1, -1, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
