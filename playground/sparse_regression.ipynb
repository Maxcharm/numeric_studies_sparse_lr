{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseLinearDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 total_sequence_length: int = 200, \n",
    "                 sparsity: int = 6,\n",
    "                 num_samples: int = 1000, \n",
    "                 noise_std: float = 0.1,\n",
    "                 input_dist: str = \"gaussian\",\n",
    "                 input_std:int = 5,\n",
    "                 input_range:tuple[float, float] = (-10, 10),\n",
    "                 true_weight_dist: str = \"gaussian\",\n",
    "                 weight_std:int = 5,\n",
    "                 weight_range:tuple[float, float] = (-10, 10),\n",
    "                 coefficient:list[int] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.active_set = torch.randperm(total_sequence_length)[:sparsity]\n",
    "        self.true_weight = torch.zeros(total_sequence_length).int()\n",
    "        self.num_samples = num_samples\n",
    "        if coefficient is not None:\n",
    "            true_weights = torch.Tensor(coefficient)\n",
    "        else:\n",
    "            if true_weight_dist == \"gaussian\":\n",
    "                true_weights = torch.randn(sparsity) * weight_std\n",
    "            else:\n",
    "                assert true_weight_dist == \"uniform\", f\"unknown distribution {true_weight_dist}.\"\n",
    "                low, high = weight_range\n",
    "                true_weights = torch.empty(sparsity).uniform_(low, high)\n",
    "        true_weights = true_weights.int()\n",
    "        self.true_weight[self.active_set] = true_weights\n",
    "        self.data = []\n",
    "        if input_dist == \"gaussian\":\n",
    "            for _ in range(num_samples):\n",
    "                x = torch.randint(0, 10, (total_sequence_length,)).int()\n",
    "                y = x @ self.true_weight + noise_std * torch.randn(1)\n",
    "                x = x.float()\n",
    "                y = y.float()\n",
    "                self.data.append((x, y))\n",
    "        else:\n",
    "            assert input_dist == \"uniform\", f\"unknown input distribution {input_dist}.\"\n",
    "            low, high = input_range\n",
    "            for _ in range(num_samples):\n",
    "                x = torch.empty(total_sequence_length).uniform_(low, high).float()\n",
    "                x = x.int()               \n",
    "                y = x @ self.true_weight + noise_std * torch.randn(1)\n",
    "                x = x.float()\n",
    "                y = y.float()\n",
    "                self.data.append((x, y.item()))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_network(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.Linear(in_features=input_dim, out_features=1)\n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_network_hidden(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.network = nn.ModuleList([\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        for layer in self.network:\n",
    "            x = layer(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    (50, 6),\n",
    "    (400, 6),\n",
    "    (1000, 6)\n",
    "]\n",
    "runs = 1\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_weight_comparison(learned_weights, true_weights, true_active_set, title=\"\", save_path=None):\n",
    "    n = len(learned_weights)\n",
    "    x = np.arange(n)\n",
    "\n",
    "    # Build color scheme\n",
    "    bar_colors = ['red' if i in true_active_set else 'blue' for i in range(n)]\n",
    "    bar_alpha = [1.0 if i in true_active_set else 0.3 for i in range(n)]\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "\n",
    "    # Plot learned weights\n",
    "    for i in range(n):\n",
    "        plt.bar(i, learned_weights[i], color=bar_colors[i], alpha=bar_alpha[i], width=0.8)\n",
    "\n",
    "    # Overlay true weights with dashed black outlines\n",
    "    plt.plot(x, true_weights, color='black', linestyle='--', linewidth=1.5, label='True Weights')\n",
    "\n",
    "    # Highlight true active set weights\n",
    "    plt.scatter(true_active_set, true_weights[true_active_set], color='black', zorder=5)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Weight Index\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: noiseless label, inputs and true weights being both i.i.d. gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/miniconda3/envs/fl/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 - Loss: 1061.6757\n",
      "Epoch 20 - Loss: 0.1280\n",
      "Epoch 40 - Loss: 0.1479\n",
      "Epoch 60 - Loss: 0.2025\n",
      "Epoch 80 - Loss: 0.1790\n",
      "Epoch 100 - Loss: 0.1659\n",
      "Epoch 120 - Loss: 0.2353\n",
      "Epoch 140 - Loss: 0.2181\n",
      "Epoch 160 - Loss: 0.1844\n",
      "Epoch 180 - Loss: 0.1693\n",
      "Epoch 200 - Loss: 0.1535\n",
      "Epoch 220 - Loss: 0.1903\n",
      "Epoch 240 - Loss: 0.2487\n",
      "Epoch 260 - Loss: 0.1622\n",
      "Epoch 280 - Loss: 0.1657\n",
      "Epoch 300 - Loss: 0.2317\n",
      "Epoch 320 - Loss: 0.0781\n",
      "Epoch 340 - Loss: 0.1648\n",
      "Epoch 360 - Loss: 0.1320\n",
      "Epoch 380 - Loss: 0.1766\n",
      "Epoch 400 - Loss: 0.1930\n",
      "Epoch 420 - Loss: 0.2154\n",
      "Epoch 440 - Loss: 0.2096\n",
      "Epoch 460 - Loss: 0.2449\n",
      "Epoch 480 - Loss: 0.1312\n",
      "Epoch 00 - Loss: 875.8969\n",
      "Epoch 20 - Loss: 10.4376\n",
      "Epoch 40 - Loss: 12.2000\n",
      "Epoch 60 - Loss: 8.9046\n",
      "Epoch 80 - Loss: 13.6201\n",
      "Epoch 100 - Loss: 12.3132\n",
      "Epoch 120 - Loss: 11.6207\n",
      "Epoch 140 - Loss: 13.9156\n",
      "Epoch 160 - Loss: 8.6433\n",
      "Epoch 180 - Loss: 11.7261\n",
      "Epoch 200 - Loss: 10.8515\n",
      "Epoch 220 - Loss: 10.3456\n",
      "Epoch 240 - Loss: 11.0494\n",
      "Epoch 260 - Loss: 11.5550\n",
      "Epoch 280 - Loss: 11.6496\n",
      "Epoch 300 - Loss: 11.9215\n",
      "Epoch 320 - Loss: 11.0292\n",
      "Epoch 340 - Loss: 12.2197\n",
      "Epoch 360 - Loss: 8.5614\n",
      "Epoch 380 - Loss: 11.7004\n",
      "Epoch 400 - Loss: 10.5707\n",
      "Epoch 420 - Loss: 12.2858\n",
      "Epoch 440 - Loss: 13.7374\n",
      "Epoch 460 - Loss: 8.3832\n",
      "Epoch 480 - Loss: 11.4790\n",
      "Epoch 00 - Loss: 264.6374\n",
      "Epoch 20 - Loss: 68.3319\n",
      "Epoch 40 - Loss: 61.7598\n",
      "Epoch 60 - Loss: 76.2097\n",
      "Epoch 80 - Loss: 56.4512\n",
      "Epoch 100 - Loss: 79.9648\n",
      "Epoch 120 - Loss: 70.7629\n",
      "Epoch 140 - Loss: 86.4246\n",
      "Epoch 160 - Loss: 79.8155\n",
      "Epoch 180 - Loss: 68.1876\n",
      "Epoch 200 - Loss: 85.5605\n",
      "Epoch 220 - Loss: 75.6210\n",
      "Epoch 240 - Loss: 67.9207\n",
      "Epoch 260 - Loss: 88.4744\n",
      "Epoch 280 - Loss: 84.4771\n",
      "Epoch 300 - Loss: 71.5882\n",
      "Epoch 320 - Loss: 76.1391\n",
      "Epoch 340 - Loss: 66.2604\n",
      "Epoch 360 - Loss: 79.0371\n",
      "Epoch 380 - Loss: 66.8086\n",
      "Epoch 400 - Loss: 70.2389\n",
      "Epoch 420 - Loss: 67.5485\n",
      "Epoch 440 - Loss: 70.1681\n",
      "Epoch 460 - Loss: 59.1541\n",
      "Epoch 480 - Loss: 69.6705\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (n,k) in configurations:\n",
    "    losses_across_runs = []\n",
    "    stored_weights = 0\n",
    "    for run_id in range(runs):\n",
    "        losses = []\n",
    "        dataset = SparseLinearDataset(total_sequence_length=n, sparsity=k, num_samples=1600, noise_std=0)\n",
    "        dataloader = DataLoader(dataset, shuffle=True)\n",
    "        true_active_set = dataset.active_set\n",
    "        true_weight = dataset.true_weight\n",
    "        model = linear_network(n)\n",
    "        model.to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 5e-3)\n",
    "\n",
    "        model.train()\n",
    "        loss_fn = nn.MSELoss()\n",
    "        for idx in range(epochs):\n",
    "            total_loss = 0\n",
    "            for (x, y) in dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                preds = model(x)\n",
    "                loss = loss_fn(preds, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "            if idx % 20 == 0:\n",
    "                print(f\"Epoch {idx:02d} - Loss: {avg_loss:.4f}\")\n",
    "            losses.append(avg_loss)\n",
    "        losses_across_runs.append(losses)\n",
    "        # After training completes per run:\n",
    "        learned_weights = model.network.weight.data.detach().cpu().squeeze()\n",
    "\n",
    "        plot_weight_comparison(\n",
    "            learned_weights=learned_weights.numpy(),\n",
    "            true_weights=true_weight.numpy(),\n",
    "            true_active_set=true_active_set,\n",
    "            title=f\"n={n}, k={k} - Learned vs True Weights\",\n",
    "            save_path=f\"../log/plots/linear/n_{n}_k_{k}.png\"\n",
    "        )\n",
    "\n",
    "    np.save(f\"../log/n_{n}_k_{k}_50runs_linear.npy\", np.array(losses_across_runs))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: noiseless label, inputs being gaussian, true weights being uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: noiseless label, inputs and true weights being both uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4: noiseless label, inputs being uniform and true weights being gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 5: noiseless label, inputs being uniform and true weights being 1, -1, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 6: noiseless label, inputs being gaussian and true weights being 1, -1, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
